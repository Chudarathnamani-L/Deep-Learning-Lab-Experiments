{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Lab 2 --> Implementing a Multi-Class Classification Model using Deep neural network"
      ],
      "metadata": {
        "id": "xjNf7PzufrcU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---------"
      ],
      "metadata": {
        "id": "gfcRSXykfv0j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1:\n",
        "* Import all the neccesary Libraries"
      ],
      "metadata": {
        "id": "x6E6pVWpfw7F"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "twdZSap-cUG9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from scipy import ndimage\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Drive mount"
      ],
      "metadata": {
        "id": "0TI03iLWf3D0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtsWN3-RdNHe",
        "outputId": "d28f8dc4-c361-4929-b8ab-8bcec38d27ab"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Give access to the Files Te.h5 and Tr.h5"
      ],
      "metadata": {
        "id": "MQ8ui5Kvf8hQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def inspect_h5_file(file_name):\n",
        "  with h5py.File(file_name,'r') as file:\n",
        "    def print_structure(name, obj):\n",
        "      print(name)\n",
        "    file.visititems(print_structure)\n",
        "\n",
        "inspect_h5_file('/content/drive/MyDrive/Deep Learning Lab Activities/Lab_2/Te (2).h5')\n",
        "inspect_h5_file('/content/drive/MyDrive/Deep Learning Lab Activities/Lab_2/Tr (2).h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exrQnPaIckpt",
        "outputId": "d8309c48-21c4-40d2-b98b-ad7e0397fd73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images\n",
            "labels\n",
            "images\n",
            "labels\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2:\n",
        "* Load the Dataset"
      ],
      "metadata": {
        "id": "ikqCUp63gN9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset():\n",
        "    train_dataset = h5py.File('/content/drive/MyDrive/Deep Learning Lab Activities/Lab_2/Tr (2).h5', \"r\")\n",
        "    train_set_x_orig = np.array(train_dataset[\"images\"][:])\n",
        "    train_set_y_orig = np.array(train_dataset[\"labels\"][:])\n",
        "\n",
        "    test_dataset = h5py.File('/content/drive/MyDrive/Deep Learning Lab Activities/Lab_2/Te (2).h5', \"r\")\n",
        "    test_set_x_orig = np.array(test_dataset[\"images\"][:])\n",
        "    test_set_y_orig = np.array(test_dataset[\"labels\"][:])\n",
        "\n",
        "    classes = np.unique(train_set_y_orig)\n",
        "\n",
        "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
        "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
        "\n",
        "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
        "\n",
        "# Load and preprocess data\n",
        "train_x_orig, train_y_orig, test_x_orig, test_y_orig, classes = load_dataset()"
      ],
      "metadata": {
        "id": "Z08L0xO7cknx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3:   Preprocess the Dataset"
      ],
      "metadata": {
        "id": "OEqhPpe9gXDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_data(train_x_orig, test_x_orig):\n",
        "    # Flatten and normalize\n",
        "    train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1) / 255.0\n",
        "    test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1) / 255.0\n",
        "\n",
        "    return train_x_flatten.T, test_x_flatten.T\n",
        "\n",
        "# Preprocess data\n",
        "train_x, test_x = preprocess_data(train_x_orig, test_x_orig)\n"
      ],
      "metadata": {
        "id": "Ao72R1OIgWx8"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Convert Labels to One-Hot Encoding"
      ],
      "metadata": {
        "id": "a7AEuNIogd_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encode(labels, num_classes):\n",
        "    return np.eye(num_classes)[labels.reshape(-1)].T\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "train_y = one_hot_encode(train_y_orig, len(classes))\n",
        "test_y = one_hot_encode(test_y_orig, len(classes))\n"
      ],
      "metadata": {
        "id": "YKaM23bdgjf-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Initialize Parameters"
      ],
      "metadata": {
        "id": "NLyW-4aQgneN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_parameters(layer_dims):\n",
        "    np.random.seed(1)\n",
        "    parameters = {}\n",
        "    L = len(layer_dims)\n",
        "\n",
        "    for l in range(1, L):\n",
        "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) * 0.01\n",
        "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "    return parameters\n"
      ],
      "metadata": {
        "id": "wsmF1nINgofd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4: Implement Forward Propagation"
      ],
      "metadata": {
        "id": "jv1TI4h7gqaV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(Z):\n",
        "    exp_Z = np.exp(Z - np.max(Z, axis=0, keepdims=True))\n",
        "    return exp_Z / np.sum(exp_Z, axis=0, keepdims=True)\n",
        "\n",
        "def relu(Z):\n",
        "    return np.maximum(0, Z)\n",
        "\n",
        "def forward_propagation(X, parameters):\n",
        "    caches = []\n",
        "    A = X\n",
        "    L = len(parameters) // 2\n",
        "\n",
        "    for l in range(1, L):\n",
        "        A_prev = A\n",
        "        Z = np.dot(parameters['W' + str(l)], A_prev) + parameters['b' + str(l)]\n",
        "        A = relu(Z)\n",
        "        caches.append((A_prev, Z))\n",
        "\n",
        "    ZL = np.dot(parameters['W' + str(L)], A) + parameters['b' + str(L)]\n",
        "    AL = softmax(ZL)\n",
        "    caches.append((A, ZL))\n",
        "\n",
        "    return AL, caches\n"
      ],
      "metadata": {
        "id": "cbeGxLySgqBZ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5: Implement Backward Propagation"
      ],
      "metadata": {
        "id": "UcmM4QP6gyjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def backward_propagation(AL, Y, caches, parameters):\n",
        "    grads = {}\n",
        "    L = len(caches)\n",
        "    m = AL.shape[1]\n",
        "\n",
        "    dZL = AL - Y\n",
        "    grads['dW' + str(L)] = np.dot(dZL, caches[L-1][0].T) / m\n",
        "    grads['db' + str(L)] = np.sum(dZL, axis=1, keepdims=True) / m\n",
        "\n",
        "    for l in reversed(range(1, L)):\n",
        "        dA = np.dot(parameters['W' + str(l+1)].T, dZL)\n",
        "        dZ = dA * (caches[l-1][1] > 0)  # ReLU derivative\n",
        "        grads['dW' + str(l)] = np.dot(dZ, caches[l-1][0].T) / m\n",
        "        grads['db' + str(l)] = np.sum(dZ, axis=1, keepdims=True) / m\n",
        "        dZL = dZ\n",
        "\n",
        "    return grads\n"
      ],
      "metadata": {
        "id": "t4eOazsugzav"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6: Update Parameters Using Gradient Descent"
      ],
      "metadata": {
        "id": "QnUx2HHNg1D1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "    L = len(parameters) // 2\n",
        "\n",
        "    for l in range(1, L+1):\n",
        "        parameters['W' + str(l)] -= learning_rate * grads['dW' + str(l)]\n",
        "        parameters['b' + str(l)] -= learning_rate * grads['db' + str(l)]\n",
        "\n",
        "    return parameters\n"
      ],
      "metadata": {
        "id": "GYHvspC6g2pw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7: Train the Model"
      ],
      "metadata": {
        "id": "ec8LA3w1g42Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model(X_train, Y_train, layers_dims, learning_rate=0.0075, num_iterations=3000):\n",
        "    parameters = initialize_parameters(layers_dims)\n",
        "\n",
        "    for i in range(num_iterations):\n",
        "        AL, caches = forward_propagation(X_train, parameters)\n",
        "        cost = -np.sum(Y_train * np.log(AL)) / Y_train.shape[1]\n",
        "        grads = backward_propagation(AL, Y_train, caches, parameters)\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Cost after iteration {i}: {cost}\")\n",
        "\n",
        "    return parameters\n"
      ],
      "metadata": {
        "id": "-Y6e_RiWg6jN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 8: Make Predictions and Evaluate the Model"
      ],
      "metadata": {
        "id": "uwX_C-Jmg-cZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, parameters):\n",
        "    AL, _ = forward_propagation(X, parameters)\n",
        "    return np.argmax(AL, axis=0)\n",
        "\n",
        "def accuracy(predictions, Y):\n",
        "    return np.mean(predictions == np.argmax(Y, axis=0)) * 100\n",
        "\n",
        "# Define the layers dimensions\n",
        "layers_dims = [train_x.shape[0], 64, 32, len(classes)]  # Example: 3 layers\n",
        "\n",
        "# Train the model\n",
        "parameters = model(train_x, train_y, layers_dims)\n",
        "\n",
        "# Test the model\n",
        "train_predictions = predict(train_x, parameters)\n",
        "test_predictions = predict(test_x, parameters)\n",
        "\n",
        "print(f\"Train Accuracy: {accuracy(train_predictions, train_y)}%\")\n",
        "print(f\"Test Accuracy: {accuracy(test_predictions, test_y)}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lDN7zi9hAIJ",
        "outputId": "e8a56bd6-0a34-42bd-8291-8b197ed2a9b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost after iteration 0: 1.6095547093839042\n",
            "Cost after iteration 100: 1.6092674945966423\n",
            "Cost after iteration 200: 1.6089591991813577\n",
            "Cost after iteration 300: 1.6085154638854235\n",
            "Cost after iteration 400: 1.6077827417891644\n",
            "Cost after iteration 500: 1.6063895043725838\n",
            "Cost after iteration 600: 1.6032586298706992\n",
            "Cost after iteration 700: 1.594881503122156\n",
            "Cost after iteration 800: 1.5714319004422415\n",
            "Cost after iteration 900: 1.5296963221996325\n",
            "Cost after iteration 1000: 1.4732951578677849\n",
            "Cost after iteration 1100: 1.3655926718972746\n",
            "Cost after iteration 1200: 1.1706488018320444\n",
            "Cost after iteration 1300: 1.0078406534158504\n",
            "Cost after iteration 1400: 0.8277944358635745\n",
            "Cost after iteration 1500: 0.6769252046990993\n",
            "Cost after iteration 1600: 0.7112029893428061\n",
            "Cost after iteration 1700: 0.3569321067698971\n",
            "Cost after iteration 1800: 0.5169079344750432\n",
            "Cost after iteration 1900: 0.22884127862918036\n",
            "Cost after iteration 2000: 0.19092676423691204\n",
            "Cost after iteration 2100: 0.13374646874777707\n",
            "Cost after iteration 2200: 0.10275442153582963\n",
            "Cost after iteration 2300: 0.07221391762930447\n",
            "Cost after iteration 2400: 0.05188572341963987\n",
            "Cost after iteration 2500: 0.037428141044526235\n",
            "Cost after iteration 2600: 0.028238178518022735\n",
            "Cost after iteration 2700: 0.022260024843191017\n",
            "Cost after iteration 2800: 0.01816400621125099\n",
            "Cost after iteration 2900: 0.015222398289127519\n",
            "Train Accuracy: 100.0%\n",
            "Test Accuracy: 38.0%\n"
          ]
        }
      ]
    }
  ]
}